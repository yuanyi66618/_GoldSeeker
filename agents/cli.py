"""
Gold-Seeker å‘½ä»¤è¡Œæ¥å£

æä¾›å‘½ä»¤è¡Œå·¥å…·ï¼Œæ”¯æŒå¿«é€Ÿæ‰§è¡Œåœ°çƒåŒ–å­¦åˆ†æä»»åŠ¡ã€‚
"""

import argparse
import sys
from pathlib import Path
from typing import Optional, List
import pandas as pd

from . import __version__, print_platform_info
from .config import load_config
from .utils import setup_logging, validate_geochemical_data
from .spatial_analyst import SpatialAnalystAgent
from .tools.geochem import GeochemSelector, GeochemProcessor, FractalAnomalyFilter, WeightsOfEvidenceCalculator


def create_parser() -> argparse.ArgumentParser:
    """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        prog="gold-seeker",
        description="Gold-Seeker: åœ°çƒåŒ–å­¦æ‰¾çŸ¿é¢„æµ‹æ™ºèƒ½å¹³å°",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  gold-seeker analyze data.csv --elements Au As Sb Hg
  gold-seeker workflow data.csv --config config.yaml
  gold-seeker validate data.csv --elements Au As Sb
  gold-seeker info
        """
    )
    
    # ç‰ˆæœ¬ä¿¡æ¯
    parser.add_argument(
        "--version", "-v",
        action="version",
        version=f"Gold-Seeker v{__version__}"
    )
    
    # å­å‘½ä»¤
    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")
    
    # åˆ†æå‘½ä»¤
    analyze_parser = subparsers.add_parser(
        "analyze",
        help="æ‰§è¡Œåœ°çƒåŒ–å­¦æ•°æ®åˆ†æ"
    )
    analyze_parser.add_argument(
        "data_file",
        help="åœ°çƒåŒ–å­¦æ•°æ®æ–‡ä»¶è·¯å¾„"
    )
    analyze_parser.add_argument(
        "--elements", "-e",
        nargs="+",
        default=["Au", "As", "Sb", "Hg"],
        help="è¦åˆ†æçš„å…ƒç´ åˆ—è¡¨"
    )
    analyze_parser.add_argument(
        "--output", "-o",
        default="output",
        help="è¾“å‡ºç›®å½•"
    )
    analyze_parser.add_argument(
        "--config", "-c",
        help="é…ç½®æ–‡ä»¶è·¯å¾„"
    )
    analyze_parser.add_argument(
        "--training-points",
        help="è®­ç»ƒç‚¹æ–‡ä»¶è·¯å¾„"
    )
    
    # å·¥ä½œæµå‘½ä»¤
    workflow_parser = subparsers.add_parser(
        "workflow",
        help="æ‰§è¡Œå®Œæ•´å·¥ä½œæµ"
    )
    workflow_parser.add_argument(
        "data_file",
        help="åœ°çƒåŒ–å­¦æ•°æ®æ–‡ä»¶è·¯å¾„"
    )
    workflow_parser.add_argument(
        "--config", "-c",
        help="é…ç½®æ–‡ä»¶è·¯å¾„"
    )
    workflow_parser.add_argument(
        "--output", "-o",
        default="output",
        help="è¾“å‡ºç›®å½•"
    )
    
    # éªŒè¯å‘½ä»¤
    validate_parser = subparsers.add_parser(
        "validate",
        help="éªŒè¯æ•°æ®è´¨é‡"
    )
    validate_parser.add_argument(
        "data_file",
        help="åœ°çƒåŒ–å­¦æ•°æ®æ–‡ä»¶è·¯å¾„"
    )
    validate_parser.add_argument(
        "--elements", "-e",
        nargs="+",
        required=True,
        help="è¦éªŒè¯çš„å…ƒç´ åˆ—è¡¨"
    )
    validate_parser.add_argument(
        "--config", "-c",
        help="é…ç½®æ–‡ä»¶è·¯å¾„"
    )
    
    # ä¿¡æ¯å‘½ä»¤
    info_parser = subparsers.add_parser(
        "info",
        help="æ˜¾ç¤ºå¹³å°ä¿¡æ¯"
    )
    
    # ç¤ºä¾‹å‘½ä»¤
    example_parser = subparsers.add_parser(
        "example",
        help="è¿è¡Œç¤ºä¾‹åˆ†æ"
    )
    example_parser.add_argument(
        "--type", "-t",
        choices=["synthetic", "workflow"],
        default="synthetic",
        help="ç¤ºä¾‹ç±»å‹"
    )
    
    return parser


def cmd_analyze(args) -> int:
    """æ‰§è¡Œåˆ†æå‘½ä»¤"""
    try:
        # åŠ è½½é…ç½®
        config = load_config(args.config)
        
        # è®¾ç½®æ—¥å¿—
        logger = setup_logging(
            level=config.get_log_level(),
            log_file=Path(args.output) / "analysis.log"
        )
        
        logger.info(f"å¼€å§‹åˆ†ææ•°æ®: {args.data_file}")
        
        # åŠ è½½æ•°æ®
        data = pd.read_csv(args.data_file)
        logger.info(f"æ•°æ®åŠ è½½å®Œæˆ: {data.shape}")
        
        # éªŒè¯æ•°æ®
        detection_limits = config.get_detection_limits()
        valid, errors = validate_geochemical_data(
            data, args.elements, detection_limits
        )
        
        if not valid:
            logger.error("æ•°æ®éªŒè¯å¤±è´¥:")
            for error in errors:
                logger.error(f"  - {error}")
            return 1
        
        # åˆ›å»ºåˆ†æå™¨
        from langchain_openai import ChatOpenAI
        llm = ChatOpenAI(**config.get_llm_config())
        analyst = SpatialAnalystAgent(llm, detection_limits)
        
        # åŠ è½½è®­ç»ƒç‚¹ï¼ˆå¦‚æœæä¾›ï¼‰
        training_points = None
        if args.training_points:
            training_points = pd.read_csv(args.training_points)
            logger.info(f"è®­ç»ƒç‚¹åŠ è½½å®Œæˆ: {training_points.shape}")
        
        # æ‰§è¡Œåˆ†æ
        result = analyst.analyze_geochemical_data(
            data=data,
            elements=args.elements,
            training_points=training_points
        )
        
        # ç”ŸæˆæŠ¥å‘Š
        report = analyst.generate_analysis_report(result)
        
        # ä¿å­˜ç»“æœ
        output_dir = Path(args.output)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = output_dir / "analysis_report.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        # ä¿å­˜ç»“æœæ•°æ®
        if hasattr(result, 'to_dict'):
            import json
            result_file = output_dir / "analysis_result.json"
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(result.to_dict(), f, indent=2, ensure_ascii=False)
        
        logger.info(f"åˆ†æå®Œæˆï¼Œç»“æœä¿å­˜åˆ°: {output_dir}")
        return 0
        
    except Exception as e:
        print(f"åˆ†æå¤±è´¥: {e}")
        return 1


def cmd_workflow(args) -> int:
    """æ‰§è¡Œå·¥ä½œæµå‘½ä»¤"""
    try:
        # è¿è¡Œå®Œæ•´å·¥ä½œæµç¤ºä¾‹
        from examples.complete_workflow import main as workflow_main
        
        # è®¾ç½®å‚æ•°
        import sys
        sys.argv = [
            "complete_workflow.py",
            "--output", args.output
        ]
        
        if args.config:
            sys.argv.extend(["--config", args.config])
        
        return workflow_main()
        
    except Exception as e:
        print(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
        return 1


def cmd_validate(args) -> int:
    """æ‰§è¡ŒéªŒè¯å‘½ä»¤"""
    try:
        # åŠ è½½é…ç½®
        config = load_config(args.config)
        
        # è®¾ç½®æ—¥å¿—
        logger = setup_logging(level=config.get_log_level())
        
        logger.info(f"éªŒè¯æ•°æ®: {args.data_file}")
        
        # åŠ è½½æ•°æ®
        data = pd.read_csv(args.data_file)
        logger.info(f"æ•°æ®åŠ è½½å®Œæˆ: {data.shape}")
        
        # éªŒè¯æ•°æ®
        detection_limits = config.get_detection_limits()
        valid, errors = validate_geochemical_data(
            data, args.elements, detection_limits
        )
        
        if valid:
            print("âœ… æ•°æ®éªŒè¯é€šè¿‡")
            return 0
        else:
            print("âŒ æ•°æ®éªŒè¯å¤±è´¥:")
            for error in errors:
                print(f"  - {error}")
            return 1
        
    except Exception as e:
        print(f"éªŒè¯å¤±è´¥: {e}")
        return 1


def cmd_info(args) -> int:
    """æ‰§è¡Œä¿¡æ¯å‘½ä»¤"""
    print_platform_info()
    return 0


def cmd_example(args) -> int:
    """æ‰§è¡Œç¤ºä¾‹å‘½ä»¤"""
    try:
        if args.type == "synthetic":
            # è¿è¡Œåˆæˆæ•°æ®ç¤ºä¾‹
            from examples.complete_workflow import generate_synthetic_data
            from examples.complete_workflow import main as workflow_main
            
            print("ğŸ”¬ è¿è¡Œåˆæˆæ•°æ®ç¤ºä¾‹...")
            return workflow_main()
        
        elif args.type == "workflow":
            # è¿è¡Œå·¥ä½œæµç¤ºä¾‹
            from examples.complete_workflow import main as workflow_main
            
            print("ğŸ”„ è¿è¡Œå®Œæ•´å·¥ä½œæµç¤ºä¾‹...")
            return workflow_main()
        
        return 0
        
    except Exception as e:
        print(f"ç¤ºä¾‹è¿è¡Œå¤±è´¥: {e}")
        return 1


def main(argv: Optional[List[str]] = None) -> int:
    """ä¸»å‡½æ•°"""
    parser = create_parser()
    args = parser.parse_args(argv)
    
    # å¦‚æœæ²¡æœ‰æä¾›å‘½ä»¤ï¼Œæ˜¾ç¤ºå¸®åŠ©
    if not args.command:
        parser.print_help()
        return 1
    
    # æ‰§è¡Œå¯¹åº”å‘½ä»¤
    if args.command == "analyze":
        return cmd_analyze(args)
    elif args.command == "workflow":
        return cmd_workflow(args)
    elif args.command == "validate":
        return cmd_validate(args)
    elif args.command == "info":
        return cmd_info(args)
    elif args.command == "example":
        return cmd_example(args)
    else:
        print(f"æœªçŸ¥å‘½ä»¤: {args.command}")
        return 1


if __name__ == "__main__":
    sys.exit(main())