# Gold-Seeker API å‚è€ƒæ–‡æ¡£

æœ¬æ–‡æ¡£æä¾›Gold-Seekeråœ°çƒåŒ–å­¦æ‰¾çŸ¿é¢„æµ‹æ™ºèƒ½å¹³å°çš„å®Œæ•´APIå‚è€ƒï¼ŒåŒ…æ‹¬æ‰€æœ‰ç±»ã€æ–¹æ³•å’Œå‡½æ•°çš„è¯¦ç»†è¯´æ˜ã€‚

## ğŸ“‹ ç›®å½•

- [æ ¸å¿ƒæ¨¡å—](#æ ¸å¿ƒæ¨¡å—)
- [ä»£ç†æ¨¡å—](#ä»£ç†æ¨¡å—)
- [å·¥å…·æ¨¡å—](#å·¥å…·æ¨¡å—)
- [é…ç½®æ¨¡å—](#é…ç½®æ¨¡å—)
- [å®ç”¨å·¥å…·](#å®ç”¨å·¥å…·)
- [CLIæ¥å£](#cliæ¥å£)
- [ç±»å‹å®šä¹‰](#ç±»å‹å®šä¹‰)

## ğŸ—ï¸ æ ¸å¿ƒæ¨¡å—

### GoldSeekerç±»

ä¸»è¦çš„å¹³å°å…¥å£ç±»ï¼Œæä¾›é«˜çº§APIæ¥å£ã€‚

```python
class GoldSeeker:
    """Gold-Seekeråœ°çƒåŒ–å­¦æ‰¾çŸ¿é¢„æµ‹å¹³å°ä¸»ç±»"""
    
    def __init__(self, config_path: Optional[str] = None, **kwargs):
        """
        åˆå§‹åŒ–Gold-Seekerå¹³å°
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            **kwargs: é¢å¤–é…ç½®å‚æ•°
        
        Example:
            >>> gs = GoldSeeker(config_path="config/my_config.yaml")
            >>> gs = GoldSeeker(data_dir="./data", n_jobs=4)
        """
    
    def quick_analyze(self, 
                     data: Union[str, pd.DataFrame, gpd.GeoDataFrame],
                     target_element: str,
                     **kwargs) -> AnalysisResult:
        """
        å¿«é€Ÿåˆ†ææ¥å£
        
        Args:
            data: è¾“å…¥æ•°æ®ï¼ˆæ–‡ä»¶è·¯å¾„æˆ–DataFrameï¼‰
            target_element: ç›®æ ‡å…ƒç´ ï¼ˆå¦‚"Au"ï¼‰
            **kwargs: é¢å¤–å‚æ•°
        
        Returns:
            AnalysisResult: åˆ†æç»“æœå¯¹è±¡
        
        Example:
            >>> result = gs.quick_analyze("data/geochem.csv", "Au")
            >>> print(result.summary)
        """
    
    def full_workflow(self, 
                     data: Union[str, pd.DataFrame, gpd.GeoDataFrame],
                     target_element: str,
                     workflow_config: Optional[Dict] = None) -> WorkflowResult:
        """
        å®Œæ•´å·¥ä½œæµç¨‹
        
        Args:
            data: è¾“å…¥æ•°æ®
            target_element: ç›®æ ‡å…ƒç´ 
            workflow_config: å·¥ä½œæµé…ç½®
        
        Returns:
            WorkflowResult: å·¥ä½œæµç»“æœ
        
        Example:
            >>> config = {"feature_selection": "r_mode", "anomaly_method": "c_a"}
            >>> result = gs.full_workflow("data.csv", "Au", config)
        """
    
    def batch_analyze(self, 
                      data_list: List[Union[str, pd.DataFrame]],
                      target_elements: List[str],
                      **kwargs) -> List[AnalysisResult]:
        """
        æ‰¹é‡åˆ†æ
        
        Args:
            data_list: æ•°æ®åˆ—è¡¨
            target_elements: ç›®æ ‡å…ƒç´ åˆ—è¡¨
            **kwargs: é¢å¤–å‚æ•°
        
        Returns:
            List[AnalysisResult]: åˆ†æç»“æœåˆ—è¡¨
        """
```

### AnalysisResultç±»

åˆ†æç»“æœå®¹å™¨ç±»ã€‚

```python
@dataclass
class AnalysisResult:
    """åˆ†æç»“æœæ•°æ®ç±»"""
    
    # è¾“å…¥ä¿¡æ¯
    input_data: pd.DataFrame
    target_element: str
    config: Dict[str, Any]
    
    # ç‰¹å¾é€‰æ‹©ç»“æœ
    selected_features: List[str]
    feature_importance: pd.Series
    
    # æ•°æ®å¤„ç†ç»“æœ
    processed_data: pd.DataFrame
    outliers_removed: int
    
    # å¼‚å¸¸æ£€æµ‹ç»“æœ
    anomaly_threshold: float
    anomaly_points: pd.DataFrame
    
    # æƒé‡åˆ†æç»“æœ
    weights: pd.DataFrame
    contrast: pd.Series
    studentized_contrast: pd.Series
    
    # ç»Ÿè®¡ä¿¡æ¯
    statistics: Dict[str, Any]
    
    # å…ƒæ•°æ®
    timestamp: datetime
    processing_time: float
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
    
    def to_json(self) -> str:
        """è½¬æ¢ä¸ºJSONæ ¼å¼"""
    
    def save(self, filepath: str) -> None:
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
    
    def plot(self, plot_type: str = "summary", **kwargs) -> None:
        """ç»˜åˆ¶ç»“æœå›¾è¡¨"""
    
    def get_summary(self) -> str:
        """è·å–ç»“æœæ‘˜è¦"""
```

## ğŸ¤– ä»£ç†æ¨¡å—

### CoordinatorAgent

ä»»åŠ¡åè°ƒä»£ç†ï¼Œè´Ÿè´£å·¥ä½œæµç¨‹ç®¡ç†ã€‚

```python
class CoordinatorAgent(BaseAgent):
    """ä»»åŠ¡åè°ƒä»£ç†"""
    
    def plan_task(self, task_description: str, context: Dict) -> WorkflowPlan:
        """
        è§„åˆ’ä»»åŠ¡
        
        Args:
            task_description: ä»»åŠ¡æè¿°
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Returns:
            WorkflowPlan: å·¥ä½œæµè®¡åˆ’
        """
    
    def coordinate_agents(self, plan: WorkflowPlan) -> Dict[str, Any]:
        """
        åè°ƒå„ä»£ç†æ‰§è¡Œä»»åŠ¡
        
        Args:
            plan: å·¥ä½œæµè®¡åˆ’
        
        Returns:
            Dict[str, Any]: æ‰§è¡Œç»“æœ
        """
    
    def monitor_progress(self, task_id: str) -> TaskStatus:
        """
        ç›‘æ§ä»»åŠ¡è¿›åº¦
        
        Args:
            task_id: ä»»åŠ¡ID
        
        Returns:
            TaskStatus: ä»»åŠ¡çŠ¶æ€
        """
```

### ArchivistAgent

çŸ¥è¯†ç®¡ç†ä»£ç†ï¼Œè´Ÿè´£çŸ¥è¯†æ£€ç´¢å’Œå›¾è°±æ„å»ºã€‚

```python
class ArchivistAgent(BaseAgent):
    """çŸ¥è¯†ç®¡ç†ä»£ç†"""
    
    def retrieve_knowledge(self, query: str, domain: str) -> List[KnowledgeItem]:
        """
        æ£€ç´¢çŸ¥è¯†
        
        Args:
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
            domain: çŸ¥è¯†åŸŸ
        
        Returns:
            List[KnowledgeItem]: çŸ¥è¯†é¡¹åˆ—è¡¨
        """
    
    def build_graph(self, entities: List[Entity], relations: List[Relation]) -> KnowledgeGraph:
        """
        æ„å»ºçŸ¥è¯†å›¾è°±
        
        Args:
            entities: å®ä½“åˆ—è¡¨
            relations: å…³ç³»åˆ—è¡¨
        
        Returns:
            KnowledgeGraph: çŸ¥è¯†å›¾è°±
        """
    
    def query_graph(self, graph: KnowledgeGraph, query: GraphQuery) -> List[GraphResult]:
        """
        æŸ¥è¯¢çŸ¥è¯†å›¾è°±
        
        Args:
            graph: çŸ¥è¯†å›¾è°±
            query: å›¾æŸ¥è¯¢
        
        Returns:
            List[GraphResult]: æŸ¥è¯¢ç»“æœ
        """
```

### ModelerAgent

å»ºæ¨¡ä»£ç†ï¼Œè´Ÿè´£æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹ã€‚

```python
class ModelerAgent(BaseAgent):
    """å»ºæ¨¡ä»£ç†"""
    
    def train_model(self, 
                   training_data: TrainingData,
                   model_type: ModelType,
                   hyperparameters: Optional[Dict] = None) -> TrainedModel:
        """
        è®­ç»ƒæ¨¡å‹
        
        Args:
            training_data: è®­ç»ƒæ•°æ®
            model_type: æ¨¡å‹ç±»å‹
            hyperparameters: è¶…å‚æ•°
        
        Returns:
            TrainedModel: è®­ç»ƒå¥½çš„æ¨¡å‹
        """
    
    def predict_probability(self, 
                           model: TrainedModel,
                           evidence_layers: List[EvidenceLayer]) -> np.ndarray:
        """
        é¢„æµ‹æˆçŸ¿æ¦‚ç‡
        
        Args:
            model: è®­ç»ƒå¥½çš„æ¨¡å‹
            evidence_layers: è¯æ®å›¾å±‚
        
        Returns:
            np.ndarray: é¢„æµ‹æ¦‚ç‡
        """
    
    def validate_model(self, 
                      model: TrainedModel,
                      validation_data: ValidationData) -> ModelValidation:
        """
        éªŒè¯æ¨¡å‹
        
        Args:
            model: è®­ç»ƒå¥½çš„æ¨¡å‹
            validation_data: éªŒè¯æ•°æ®
        
        Returns:
            ModelValidation: éªŒè¯ç»“æœ
        """
```

### CriticAgent

è¯„ä¼°ä»£ç†ï¼Œè´Ÿè´£ç»“æœéªŒè¯å’ŒæŠ¥å‘Šç”Ÿæˆã€‚

```python
class CriticAgent(BaseAgent):
    """è¯„ä¼°ä»£ç†"""
    
    def validate_logic(self, results: Dict[str, Any]) -> ValidationResult:
        """
        éªŒè¯é€»è¾‘ä¸€è‡´æ€§
        
        Args:
            results: åˆ†æç»“æœ
        
        Returns:
            ValidationResult: éªŒè¯ç»“æœ
        """
    
    def assess_risk(self, predictions: np.ndarray, confidence: np.ndarray) -> RiskAssessment:
        """
        è¯„ä¼°é£é™©
        
        Args:
            predictions: é¢„æµ‹ç»“æœ
            confidence: ç½®ä¿¡åº¦
        
        Returns:
            RiskAssessment: é£é™©è¯„ä¼°
        """
    
    def generate_report(self, 
                       results: Dict[str, Any],
                       template: Optional[str] = None) -> ExplorationReport:
        """
        ç”ŸæˆæŠ¥å‘Š
        
        Args:
            results: åˆ†æç»“æœ
            template: æŠ¥å‘Šæ¨¡æ¿
        
        Returns:
            ExplorationReport: å‹˜æ¢æŠ¥å‘Š
        """
```

### SpatialAnalystAgent

ç©ºé—´åˆ†æä»£ç†ï¼Œé›†æˆLangChainè¿›è¡Œæ™ºèƒ½åˆ†æã€‚

```python
class SpatialAnalystAgent(BaseAgent):
    """ç©ºé—´åˆ†æä»£ç†"""
    
    def __init__(self, llm: Optional[BaseLanguageModel] = None, **kwargs):
        """
        åˆå§‹åŒ–ç©ºé—´åˆ†æä»£ç†
        
        Args:
            llm: è¯­è¨€æ¨¡å‹å®ä¾‹
            **kwargs: é¢å¤–å‚æ•°
        """
    
    def analyze_geochemical_data(self, 
                                data: pd.DataFrame,
                                target_element: str,
                                analysis_type: str = "full") -> Dict[str, Any]:
        """
        åˆ†æåœ°çƒåŒ–å­¦æ•°æ®
        
        Args:
            data: åœ°çƒåŒ–å­¦æ•°æ®
            target_element: ç›®æ ‡å…ƒç´ 
            analysis_type: åˆ†æç±»å‹
        
        Returns:
            Dict[str, Any]: åˆ†æç»“æœ
        """
    
    def process_single_element(self, 
                              data: pd.DataFrame,
                              element: str) -> Dict[str, Any]:
        """
        å¤„ç†å•ä¸ªå…ƒç´ 
        
        Args:
            data: æ•°æ®
            element: å…ƒç´ åç§°
        
        Returns:
            Dict[str, Any]: å¤„ç†ç»“æœ
        """
    
    def generate_analysis_report(self, results: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆåˆ†ææŠ¥å‘Š
        
        Args:
            results: åˆ†æç»“æœ
        
        Returns:
            str: æŠ¥å‘Šæ–‡æœ¬
        """
```

## ğŸ› ï¸ å·¥å…·æ¨¡å—

### GeochemSelector

åœ°çƒåŒ–å­¦ç‰¹å¾é€‰æ‹©å·¥å…·ã€‚

```python
class GeochemSelector:
    """åœ°çƒåŒ–å­¦ç‰¹å¾é€‰æ‹©å™¨"""
    
    def __init__(self, config: Optional[Dict] = None):
        """
        åˆå§‹åŒ–ç‰¹å¾é€‰æ‹©å™¨
        
        Args:
            config: é…ç½®å‚æ•°
        """
    
    def perform_r_mode_analysis(self, 
                               data: pd.DataFrame,
                               target_element: str) -> Tuple[pd.DataFrame, List[str]]:
        """
        æ‰§è¡ŒRå‹èšç±»åˆ†æ
        
        Args:
            data: è¾“å…¥æ•°æ®
            target_element: ç›®æ ‡å…ƒç´ 
        
        Returns:
            Tuple[pd.DataFrame, List[str]]: ç›¸å…³æ€§çŸ©é˜µå’Œé€‰æ‹©çš„ç‰¹å¾
        """
    
    def analyze_pca_loadings(self, 
                            data: pd.DataFrame,
                            n_components: int = 5) -> Tuple[np.ndarray, List[str]]:
        """
        åˆ†æPCAè½½è·
        
        Args:
            data: è¾“å…¥æ•°æ®
            n_components: ä¸»æˆåˆ†æ•°é‡
        
        Returns:
            Tuple[np.ndarray, List[str]]: è½½è·çŸ©é˜µå’Œé‡è¦ç‰¹å¾
        """
    
    def rank_element_importance(self, 
                               data: pd.DataFrame,
                               target_element: str,
                               method: str = "correlation") -> pd.Series:
        """
        æ’åºå…ƒç´ é‡è¦æ€§
        
        Args:
            data: è¾“å…¥æ•°æ®
            target_element: ç›®æ ‡å…ƒç´ 
            method: é‡è¦æ€§è®¡ç®—æ–¹æ³•
        
        Returns:
            pd.Series: å…ƒç´ é‡è¦æ€§æ’åº
        """
```

### GeochemProcessor

åœ°çƒåŒ–å­¦æ•°æ®å¤„ç†å·¥å…·ã€‚

```python
class GeochemProcessor:
    """åœ°çƒåŒ–å­¦æ•°æ®å¤„ç†å™¨"""
    
    def __init__(self, config: Optional[Dict] = None):
        """
        åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨
        
        Args:
            config: é…ç½®å‚æ•°
        """
    
    def impute_censored_data(self, 
                            data: pd.DataFrame,
                            detection_limits: Dict[str, float],
                            method: str = "rosner") -> pd.DataFrame:
        """
        æ’è¡¥åˆ å¤±æ•°æ®
        
        Args:
            data: è¾“å…¥æ•°æ®
            detection_limits: æ£€æµ‹é™å­—å…¸
            method: æ’è¡¥æ–¹æ³•
        
        Returns:
            pd.DataFrame: å¤„ç†åçš„æ•°æ®
        """
    
    def transform_clr(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        ä¸­å¿ƒå¯¹æ•°æ¯”å˜æ¢
        
        Args:
            data: è¾“å…¥æ•°æ®
        
        Returns:
            pd.DataFrame: CLRå˜æ¢åçš„æ•°æ®
        """
    
    def detect_outliers(self, 
                        data: pd.DataFrame,
                        method: str = "iqr") -> pd.DataFrame:
        """
        æ£€æµ‹å¼‚å¸¸å€¼
        
        Args:
            data: è¾“å…¥æ•°æ®
            method: æ£€æµ‹æ–¹æ³•
        
        Returns:
            pd.DataFrame: å¼‚å¸¸å€¼æ ‡è®°
        """
```

### FractalAnomalyFilter

åˆ†å½¢å¼‚å¸¸è¿‡æ»¤å™¨ã€‚

```python
class FractalAnomalyFilter:
    """åˆ†å½¢å¼‚å¸¸è¿‡æ»¤å™¨"""
    
    def __init__(self, config: Optional[Dict] = None):
        """
        åˆå§‹åŒ–åˆ†å½¢è¿‡æ»¤å™¨
        
        Args:
            config: é…ç½®å‚æ•°
        """
    
    def plot_ca_loglog(self, 
                      data: np.ndarray,
                      bins: int = 100) -> Tuple[np.ndarray, np.ndarray]:
        """
        ç»˜åˆ¶C-AåŒå¯¹æ•°å›¾
        
        Args:
            data: è¾“å…¥æ•°æ®
            bins: åˆ†ç®±æ•°é‡
        
        Returns:
            Tuple[np.ndarray, np.ndarray]: é¢ç§¯å’Œæµ“åº¦æ•°ç»„
        """
    
    def calculate_threshold_interactive(self, 
                                      data: np.ndarray,
                                      method: str = "knee") -> float:
        """
        äº¤äº’å¼è®¡ç®—é˜ˆå€¼
        
        Args:
            data: è¾“å…¥æ•°æ®
            method: é˜ˆå€¼è®¡ç®—æ–¹æ³•
        
        Returns:
            float: å¼‚å¸¸é˜ˆå€¼
        """
    
    def filter_anomalies(self, 
                        data: pd.DataFrame,
                        element: str,
                        threshold: float) -> pd.DataFrame:
        """
        è¿‡æ»¤å¼‚å¸¸å€¼
        
        Args:
            data: è¾“å…¥æ•°æ®
            element: å…ƒç´ åç§°
            threshold: é˜ˆå€¼
        
        Returns:
            pd.DataFrame: å¼‚å¸¸ç‚¹æ•°æ®
        """
```

### WeightsOfEvidenceCalculator

è¯æ®æƒé‡è®¡ç®—å™¨ã€‚

```python
class WeightsOfEvidenceCalculator:
    """è¯æ®æƒé‡è®¡ç®—å™¨"""
    
    def __init__(self, config: Optional[Dict] = None):
        """
        åˆå§‹åŒ–æƒé‡è®¡ç®—å™¨
        
        Args:
            config: é…ç½®å‚æ•°
        """
    
    def calculate_studentized_contrast(self, 
                                      w_plus: np.ndarray,
                                      w_minus: np.ndarray,
                                      s2_w_plus: np.ndarray,
                                      s2_w_minus: np.ndarray) -> np.ndarray:
        """
        è®¡ç®—å­¦ç”ŸåŒ–å¯¹æ¯”åº¦
        
        Args:
            w_plus: æ­£æƒé‡
            w_minus: è´Ÿæƒé‡
            s2_w_plus: æ­£æƒé‡æ–¹å·®
            s2_w_minus: è´Ÿæƒé‡æ–¹å·®
        
        Returns:
            np.ndarray: å­¦ç”ŸåŒ–å¯¹æ¯”åº¦
        """
    
    def calculate_weights(self, 
                         evidence: np.ndarray,
                         target: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        è®¡ç®—è¯æ®æƒé‡
        
        Args:
            evidence: è¯æ®æ•°æ®
            target: ç›®æ ‡å˜é‡
        
        Returns:
            Tuple[np.ndarray, np.ndarray, np.ndarray]: W+, W-, Contrast
        """
    
    def validate_significance(self, 
                             contrast: np.ndarray,
                             studentized_contrast: np.ndarray,
                             alpha: float = 0.05) -> np.ndarray:
        """
        éªŒè¯ç»Ÿè®¡æ˜¾è‘—æ€§
        
        Args:
            contrast: å¯¹æ¯”åº¦
            studentized_contrast: å­¦ç”ŸåŒ–å¯¹æ¯”åº¦
            alpha: æ˜¾è‘—æ€§æ°´å¹³
        
        Returns:
            np.ndarray: æ˜¾è‘—æ€§æ ‡è®°
        """
```

## âš™ï¸ é…ç½®æ¨¡å—

### ConfigManager

é…ç½®ç®¡ç†å™¨ã€‚

```python
class ConfigManager:
    """é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self, config_path: Optional[str] = None):
        """
        åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
    
    def get(self, key: str, default: Any = None) -> Any:
        """
        è·å–é…ç½®å€¼
        
        Args:
            key: é…ç½®é”®
            default: é»˜è®¤å€¼
        
        Returns:
            Any: é…ç½®å€¼
        """
    
    def set(self, key: str, value: Any) -> None:
        """
        è®¾ç½®é…ç½®å€¼
        
        Args:
            key: é…ç½®é”®
            value: é…ç½®å€¼
        """
    
    def save(self, filepath: str) -> None:
        """
        ä¿å­˜é…ç½®åˆ°æ–‡ä»¶
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
        """
    
    def update(self, updates: Dict[str, Any]) -> None:
        """
        æ‰¹é‡æ›´æ–°é…ç½®
        
        Args:
            updates: æ›´æ–°å­—å…¸
        """
    
    def get_detection_limits(self) -> Dict[str, float]:
        """
        è·å–æ£€æµ‹é™é…ç½®
        
        Returns:
            Dict[str, float]: æ£€æµ‹é™å­—å…¸
        """
```

## ğŸ› ï¸ å®ç”¨å·¥å…·

### æ—¥å¿—å·¥å…·

```python
def setup_logging(level: str = "INFO", 
                 log_file: Optional[str] = None,
                 format_string: Optional[str] = None) -> logging.Logger:
    """
    è®¾ç½®æ—¥å¿—è®°å½•
    
    Args:
        level: æ—¥å¿—çº§åˆ«
        log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„
        format_string: æ—¥å¿—æ ¼å¼å­—ç¬¦ä¸²
    
    Returns:
        logging.Logger: é…ç½®å¥½çš„æ—¥å¿—è®°å½•å™¨
    """

def get_logger(name: str) -> logging.Logger:
    """
    è·å–æ—¥å¿—è®°å½•å™¨
    
    Args:
        name: æ—¥å¿—è®°å½•å™¨åç§°
    
    Returns:
        logging.Logger: æ—¥å¿—è®°å½•å™¨
    """
```

### æ•°æ®éªŒè¯å·¥å…·

```python
def validate_data(data: pd.DataFrame, 
                 required_columns: List[str],
                 check_geometry: bool = False) -> bool:
    """
    éªŒè¯æ•°æ®æ ¼å¼
    
    Args:
        data: è¾“å…¥æ•°æ®
        required_columns: å¿…éœ€åˆ—
        check_geometry: æ˜¯å¦æ£€æŸ¥å‡ ä½•ä¿¡æ¯
    
    Returns:
        bool: éªŒè¯ç»“æœ
    """

def validate_geochemical_data(data: pd.DataFrame) -> Dict[str, Any]:
    """
    éªŒè¯åœ°çƒåŒ–å­¦æ•°æ®
    
    Args:
        data: è¾“å…¥æ•°æ®
    
    Returns:
        Dict[str, Any]: éªŒè¯ç»“æœ
    """
```

### æ–‡ä»¶æ“ä½œå·¥å…·

```python
def load_data(filepath: str, **kwargs) -> pd.DataFrame:
    """
    åŠ è½½æ•°æ®æ–‡ä»¶
    
    Args:
        filepath: æ–‡ä»¶è·¯å¾„
        **kwargs: é¢å¤–å‚æ•°
    
    Returns:
        pd.DataFrame: åŠ è½½çš„æ•°æ®
    """

def save_results(results: Dict[str, Any], 
                filepath: str,
                format: str = "json") -> None:
    """
    ä¿å­˜ç»“æœ
    
    Args:
        results: ç»“æœæ•°æ®
        filepath: æ–‡ä»¶è·¯å¾„
        format: ä¿å­˜æ ¼å¼
    """

def create_output_directory(base_dir: str, 
                           analysis_name: str) -> str:
    """
    åˆ›å»ºè¾“å‡ºç›®å½•
    
    Args:
        base_dir: åŸºç¡€ç›®å½•
        analysis_name: åˆ†æåç§°
    
    Returns:
        str: è¾“å‡ºç›®å½•è·¯å¾„
    """
```

## ğŸ’» CLIæ¥å£

### ä¸»å‘½ä»¤

```bash
gold-seeker [OPTIONS] COMMAND [ARGS]...
```

### å­å‘½ä»¤

#### analyze

```bash
gold-seeker analyze [OPTIONS] INPUT_FILE TARGET_ELEMENT
```

é€‰é¡¹ï¼š
- `--config PATH`: é…ç½®æ–‡ä»¶è·¯å¾„
- `--output PATH`: è¾“å‡ºç›®å½•
- `--method TEXT`: åˆ†ææ–¹æ³•
- `--elements TEXT`: æŒ‡å®šå…ƒç´ åˆ—è¡¨
- `--parallel`: å¯ç”¨å¹¶è¡Œå¤„ç†
- `--n-jobs INTEGER`: å¹¶è¡Œä½œä¸šæ•°
- `--verbose`: è¯¦ç»†è¾“å‡º

#### workflow

```bash
gold-seeker workflow [OPTIONS] INPUT_FILE TARGET_ELEMENT
```

é€‰é¡¹ï¼š
- `--config PATH`: é…ç½®æ–‡ä»¶è·¯å¾„
- `--workflow-config PATH`: å·¥ä½œæµé…ç½®æ–‡ä»¶
- `--output PATH`: è¾“å‡ºç›®å½•
- `--save-intermediate`: ä¿å­˜ä¸­é—´ç»“æœ

#### validate

```bash
gold-seeker validate [OPTIONS]
```

é€‰é¡¹ï¼š
- `--config PATH`: é…ç½®æ–‡ä»¶è·¯å¾„
- `--data PATH`: æ•°æ®æ–‡ä»¶è·¯å¾„
- `--check-all`: æ£€æŸ¥æ‰€æœ‰ç»„ä»¶

#### info

```bash
gold-seeker info [OPTIONS]
```

é€‰é¡¹ï¼š
- `--version`: æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯
- `--system`: æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
- `--dependencies`: æ˜¾ç¤ºä¾èµ–ä¿¡æ¯

#### example

```bash
gold-seeker example [OPTIONS]
```

é€‰é¡¹ï¼š
- `--dataset TEXT`: æ•°æ®é›†åç§°
- `--output PATH`: è¾“å‡ºç›®å½•
- `--run`: è¿è¡Œç¤ºä¾‹

## ğŸ“ ç±»å‹å®šä¹‰

### æ•°æ®ç±»å‹

```python
# åŸºç¡€æ•°æ®ç±»å‹
DataFrame = pd.DataFrame
GeoDataFrame = gpd.GeoDataFrame
NDArray = np.ndarray

# é…ç½®ç±»å‹
ConfigDict = Dict[str, Any]
AnalysisConfig = Dict[str, Any]

# ç»“æœç±»å‹
AnalysisResult = Dict[str, Any]
WorkflowResult = Dict[str, Any]
ValidationResult = Dict[str, Any]

# åœ°ç†ç±»å‹
Geometry = shapely.geometry.base.BaseGeometry
CRS = pyproj.CRS

# æ—¶é—´ç±»å‹
Timestamp = datetime
TimeDelta = timedelta
```

### æšä¸¾ç±»å‹

```python
class ModelType(Enum):
    """æ¨¡å‹ç±»å‹æšä¸¾"""
    LOGISTIC_REGRESSION = "logistic_regression"
    RANDOM_FOREST = "random_forest"
    GRADIENT_BOOSTING = "gradient_boosting"
    NEURAL_NETWORK = "neural_network"
    WEIGHTS_OF_EVIDENCE = "weights_of_evidence"

class AnalysisMethod(Enum):
    """åˆ†ææ–¹æ³•æšä¸¾"""
    R_MODE_CLUSTERING = "r_mode_clustering"
    PCA_ANALYSIS = "pca_analysis"
    CORRELATION_ANALYSIS = "correlation_analysis"
    MUTUAL_INFORMATION = "mutual_information"

class AnomalyMethod(Enum):
    """å¼‚å¸¸æ£€æµ‹æ–¹æ³•æšä¸¾"""
    C_A_FRACTAL = "c_a_fractal"
    CONCENTRATION_AREA = "concentration_area"
    STATISTICAL_THRESHOLD = "statistical_threshold"
    MACHINE_LEARNING = "machine_learning"
```

### æ•°æ®ç±»

```python
@dataclass
class Task:
    """ä»»åŠ¡æ•°æ®ç±»"""
    id: str
    description: str
    priority: int
    status: str
    created_at: datetime
    updated_at: datetime

@dataclass
class WorkflowPlan:
    """å·¥ä½œæµè®¡åˆ’æ•°æ®ç±»"""
    tasks: List[Task]
    dependencies: Dict[str, List[str]]
    estimated_duration: timedelta
    resources: Dict[str, Any]

@dataclass
class KnowledgeItem:
    """çŸ¥è¯†é¡¹æ•°æ®ç±»"""
    id: str
    title: str
    content: str
    source: str
    confidence: float
    metadata: Dict[str, Any]

@dataclass
class EvidenceLayer:
    """è¯æ®å±‚æ•°æ®ç±»"""
    name: str
    data: GeoDataFrame
    weight: float
    confidence: float
    metadata: Dict[str, Any]
```

---

æœ¬APIå‚è€ƒæ–‡æ¡£æä¾›äº†Gold-Seekerå¹³å°çš„å®Œæ•´æ¥å£è¯´æ˜ã€‚å¦‚éœ€æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è€ƒæºä»£ç ä¸­çš„æ–‡æ¡£å­—ç¬¦ä¸²å’Œç±»å‹æ³¨è§£ã€‚